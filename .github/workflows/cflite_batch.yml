name: ClusterFuzzLite batch fuzzing
on:
  # For testing: trigger on push to feat/fuzz branch
  push:
    branches:
      - feat/fuzz
  schedule:
    # Run every 6 hours: 00:00, 06:00, 12:00, 18:00
    - cron: '0 */6 * * *'
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      fuzz-seconds:
        description: 'Fuzzing duration in 60 seconds'
        required: false
        default: '60'
        type: string

permissions:
  contents: read
  security-events: write

# ==============================================================================
# Storage Repository Configuration for Organization
# ==============================================================================
# Required secrets/variables:
#   - Secret: CLUSTERFUZZLITE_STORAGE_TOKEN (PAT with repo write access)
#   - Variable: CLUSTERFUZZLITE_STORAGE_REPO (e.g., morph-l2/fuzz_corpora)
#
# Note: GitHub Actions has a 6-hour job time limit.
# ClusterFuzzLite will automatically run all compiled fuzzers in round-robin.
# ==============================================================================

env:
  STORAGE_REPO_URL: ${{ secrets.CLUSTERFUZZLITE_STORAGE_TOKEN && vars.CLUSTERFUZZLITE_STORAGE_REPO && format('https://{0}@github.com/{1}.git', secrets.CLUSTERFUZZLITE_STORAGE_TOKEN, vars.CLUSTERFUZZLITE_STORAGE_REPO) || '' }}
  STORAGE_REPO_BRANCH: main
  # push: 120s (2min), schedule: 120s (2min), manual: use input
  FUZZ_SECONDS: ${{ github.event_name == 'push' && '120' || github.event_name == 'schedule' && '120' || inputs.fuzz-seconds || '19800' }}

jobs:
  BatchFuzzing:
    runs-on: ubuntu-latest
    steps:
      - name: Build Fuzzers
        id: build
        uses: google/clusterfuzzlite/actions/build_fuzzers@v1
        with:
          language: go
          github-token: ${{ secrets.GITHUB_TOKEN }}
          sanitizer: address
          # Keep all fuzzers on push (disable incremental analysis for testing)
          keep-unaffected-fuzz-targets: ${{ github.event_name == 'push' }}
          storage-repo: ${{ github.event_name != 'push' && env.STORAGE_REPO_URL || '' }}
          storage-repo-branch: ${{ env.STORAGE_REPO_BRANCH }}

      - name: Run Fuzzers
        id: run
        uses: google/clusterfuzzlite/actions/run_fuzzers@v1
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          fuzz-seconds: ${{ env.FUZZ_SECONDS }}
          mode: 'batch'
          sanitizer: address
          output-sarif: true
          parallel-fuzzing: true
          # Don't pass storage-repo on push to disable incremental analysis
          storage-repo: ${{ github.event_name != 'push' && env.STORAGE_REPO_URL || '' }}
          storage-repo-branch: ${{ env.STORAGE_REPO_BRANCH }}

      - name: Upload Crash
        uses: actions/upload-artifact@v4
        if: failure() && steps.run.outcome == 'failure'
        with:
          name: crash-artifacts
          path: ./out/artifacts
          retention-days: 90

      - name: Create enhanced SARIF with crash information
        if: always() && steps.run.outcome != 'skipped'
        run: |
          python3 << 'EOF'
          import json
          import os
          import glob
          import re

          original_sarif_path = "./cifuzz-sarif/results.sarif"
          enhanced_sarif_path = "./enhanced-results.sarif"
          artifacts_path = "./out/artifacts"

          # Check if original SARIF file exists
          if not os.path.exists(original_sarif_path):
              print("No SARIF file found, skipping")
              exit(0)

          # Read existing SARIF
          with open(original_sarif_path, 'r') as f:
              sarif = json.load(f)

          # Find all crash files
          crash_files = []
          if os.path.exists(artifacts_path):
              crash_files = glob.glob(f"{artifacts_path}/**/crash-*", recursive=True)
              crash_files.extend(glob.glob(f"{artifacts_path}/**/leak-*", recursive=True))
              crash_files.extend(glob.glob(f"{artifacts_path}/**/timeout-*", recursive=True))

          print(f"Found {len(crash_files)} crash artifacts")

          # If no crashes found, copy original SARIF as-is
          if not crash_files:
              print("No crashes to add to SARIF, using original")
              with open(enhanced_sarif_path, 'w') as f:
                  json.dump(sarif, f, indent=2)
              exit(0)

          # Map fuzzer names to source file paths
          # This mapping should cover all fuzzers in the repository
          fuzzer_to_source = {
              "bn256": "tests/fuzzers/bn256/bn256_fuzz.go",
              "bls12381": "tests/fuzzers/bls12381/precompile_fuzzer.go",
              "difficulty": "tests/fuzzers/difficulty/difficulty-fuzz.go",
              "bitutil": "tests/fuzzers/bitutil/compress_fuzz.go",
              "keystore": "tests/fuzzers/keystore/keystore-fuzzer.go",
              "runtime": "tests/fuzzers/runtime/runtime_fuzz.go",
              "stacktrie": "tests/fuzzers/stacktrie/trie_fuzzer.go",
              "rlp": "tests/fuzzers/rlp/rlp_fuzzer.go",
              "abi": "tests/fuzzers/abi/abifuzzer.go",
              "secp256k1": "tests/fuzzers/secp256k1/secp_fuzzer.go",
              "trie": "tests/fuzzers/trie/trie-fuzzer.go",
              "txfetcher": "tests/fuzzers/txfetcher/txfetcher_fuzzer.go",
              "vflux": "tests/fuzzers/vflux/client-fuzzer.go",
              "bn256_cloudflare": "tests/fuzzers/bn256/bn256_fuzz.go",
              "bn256_google": "tests/fuzzers/bn256/bn256_fuzz.go",
          }

          # Add results for each crash
          results = []
          for crash_file in crash_files:
              crash_name = os.path.basename(crash_file)

              # Extract fuzzer name from directory structure
              # Path format: ./out/artifacts/fuzz_<fuzzer_name>/<sanitizer>/crash-*
              path_parts = crash_file.split(os.sep)
              fuzzer_dir = None
              for part in path_parts:
                  if part.startswith("fuzz_"):
                      fuzzer_dir = part.replace("fuzz_", "")
                      break

              if not fuzzer_dir:
                  fuzzer_dir = os.path.basename(os.path.dirname(crash_file))

              # Map fuzzer directory name to source file
              source_file = None
              for fuzzer_key, source_path in fuzzer_to_source.items():
                  if fuzzer_key in fuzzer_dir.lower():
                      source_file = source_path
                      break

              # Fallback: if no mapping found, try to find the fuzzer file
              if not source_file:
                  # Try to find a matching fuzzer file
                  fuzzer_pattern = f"tests/fuzzers/{fuzzer_dir}/*_fuzz*.go"
                  matching_files = glob.glob(fuzzer_pattern)
                  if matching_files:
                      source_file = matching_files[0]
                  else:
                      # Ultimate fallback: use a generic path
                      source_file = f"tests/fuzzers/{fuzzer_dir}"

              # Determine crash type from filename
              if crash_name.startswith("crash-"):
                  rule_id = "no-crashes"
                  message = f"Fuzzer '{fuzzer_dir}' found a crash"
              elif crash_name.startswith("leak-"):
                  rule_id = "direct-leak"
                  message = f"Fuzzer '{fuzzer_dir}' found a memory leak"
              elif crash_name.startswith("timeout-"):
                  rule_id = "no-crashes"
                  message = f"Fuzzer '{fuzzer_dir}' caused a timeout"
              else:
                  rule_id = "no-crashes"
                  message = f"Fuzzer '{fuzzer_dir}' found an issue"

              # Read crash summary if available
              summary_file = crash_file + ".summary" if not crash_file.endswith(".summary") else crash_file
              if os.path.exists(summary_file):
                  try:
                      with open(summary_file, 'r', errors='ignore') as f:
                          summary_content = f.read(1000)  # Read first 1000 chars
                          if summary_content:
                              message += f"\n\nCrash summary:\n{summary_content}"
                  except:
                      pass

              result = {
                  "ruleId": rule_id,
                  "level": "error",
                  "message": {
                      "text": message
                  },
                  "locations": [{
                      "physicalLocation": {
                          "artifactLocation": {
                              "uri": source_file
                          }
                      }
                  }]
              }
              results.append(result)

          # Update SARIF with results
          sarif["runs"][0]["results"] = results

          # Write enhanced SARIF to a new location (outside cifuzz-sarif directory)
          with open(enhanced_sarif_path, 'w') as f:
              json.dump(sarif, f, indent=2)

          print(f"Created enhanced SARIF with {len(results)} crash results")
          for result in results:
              print(f"  - {result['message']['text'][:50]}... -> {result['locations'][0]['physicalLocation']['artifactLocation']['uri']}")
          EOF

      - name: Check SARIF file exists
        id: sarif-check
        if: always() && steps.run.outcome != 'skipped'
        run: |
          if [ -f "./enhanced-results.sarif" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "No SARIF file generated"
          fi

      - name: Upload SARIF
        uses: github/codeql-action/upload-sarif@v4
        if: always() && steps.sarif-check.outputs.exists == 'true'
        with:
          sarif_file: ./enhanced-results.sarif
        continue-on-error: true
